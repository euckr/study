{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 83강 특이값 분해 (SVD)\n",
    "\n",
    "- 관련 영상: [쑤튜브 83강](https://www.youtube.com/watch?v=gxdJYNIvOI0)\n",
    "- Singular Value Decomposition\n",
    "- 지난 시간에 알아본 EVD는 대칭행렬이라는 제약이 있음\n",
    "- SVD는 대칭행렬이 아닐 경우에도 해볼 수 있는 방법이다\n",
    "\n",
    "\n",
    "\n",
    "## 개요\n",
    "- 고유값 분해에서\n",
    "    - 행렬 A는 정방, 대칭행렬\n",
    "    - $ A=PDP^T \\quad $ (P는 직교행렬, D는 대각행렬)} \n",
    "- 특이값 분해에서\n",
    "    - 행렬 A는 정방, 꼭 대칭행렬이 아니더라도\n",
    "    - $ A=UDV^T \\quad $ (U,V는 직교행렬}\n",
    "    - 이런식으로 양쪽에 똑같은 P행렬이 아닌, U,V행렬을 곱하는 방식으로도 분해를 할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD\n",
    "- A는 n차 정방행렬, 꼭 대칭행렬일 필요는 없다.\n",
    "- rank(A)=k 라면, $A=U \\, \\Sigma \\, V^T$\n",
    "- U,V는 직교행렬\n",
    "- $\\Sigma $ 는 대각행렬인데, 대각성분이 랭크(=k)개 만큼만 값이 존재, 나머지 대각요소는 0\n",
    "- $\\Sigma $ 는 요렇게 생겼다.\n",
    "\n",
    "$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sigma_{1}         &                    &         &                    &   &        & \\\\\n",
    "                   & \\sigma_{2}         &         &                    &   &        & \\\\\n",
    "                   &                    & \\ddots  &                    &   &        & \\\\\n",
    "                   &                    &         & \\sigma_{k}         &   &        & \\\\\n",
    "                   &                    &         &                    & 0 &        & \\\\\n",
    "                   &                    &         &                    &   & \\ddots & \\\\\n",
    "                   &                    &         &                    &   &        & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "$ ( $n \\times n $ 대각행렬 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뭐를 하려고? 증명!\n",
    "> A를 $A=U \\, \\Sigma \\, V^T$ 이런 꼴로 분해할 수 있다. \n",
    "\n",
    "이 사실을 증명하려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 지식\n",
    "- $ A^T A$는 대칭행렬, 전치해보면 자기 자신이니까 대칭행렬 $\\Rightarrow \\quad (A^TA)^T = A^TA $\n",
    "\n",
    "- $ rank(A) = rank(A^T A) $\n",
    "\n",
    "- 내적할 때 $ A u \\cdot v = u \\cdot A^T v \\quad \\Rightarrow $ A를 transpose해서 앞으로 뒤로 이동할 수 있다. \n",
    "[쑤튜브 17강 참고 - 대각합](https://www.youtube.com/watch?v=1W41Src9vv0&list=PLdEdazAwz5Q_n47tqf0QY94ASCmWqeGX1&index=19&t=0s)\n",
    "\n",
    "- 정규직교 기저 만드는 법을 알고 있어야 한다.[쑤튜브 71강 참고 - 정규직교기저 찾는 기술](https://www.youtube.com/watch?v=tk6HM0YVL5E&list=PLdEdazAwz5Q_n47tqf0QY94ASCmWqeGX1&index=79)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 증명\n",
    "- $A^TA = V \\, D \\, U^T $ 직교대각화를 했다고 하자.\n",
    "- $ D = \\lambda_1 \\cdots \\lambda_n $ 의 n차 대각행렬\n",
    "- $ V = [ v_1 \\cdots v_n ] \\quad $ (V는 n차 정방행렬, $v_i$ 는 열벡터)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ \\lambda \\ge 0 $이다. Why?\n",
    "    - $\n",
    "        \\lVert A x^2 \\rVert = Ax \\cdot Ax = x \\cdot A^T A x = x \\cdot \\lambda x = \\lambda (x \\cdot x ) = \\lambda \\lVert x^2 \\rVert\n",
    "      $\n",
    "    - $ \\lVert x^2 \\rVert \\ge 0 $이므로 $ \\lambda \\ge 0 $ 이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ rank(A^T A) = k $ 이므로 $ \\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_k \\ge 0 $이다. Why?\n",
    "    - D행렬의 $\\lambda$들 중에서 $ \\lambda_1 \\quad \\cdots \\quad \\lambda_k \\quad \\lambda_{k+1} \\quad \\cdots \\quad \\lambda_{n} $\n",
    "    - $ \\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_k \\ge 0 $이고\n",
    "    - $\\lambda_{k+1} = \\cdots = \\lambda_{n} = 0 $ 이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ \\{ Av_1,Av_2, \\cdots , Av_n \\} $들은 직교집합이다. Why?\n",
    "    - $ v_1 \\cdots v_n $은 직교한다는 사실은 이미 알고 있다. $ \\Rightarrow v_i \\cdot v_j = 0 $\n",
    "    - $ \\{ Av_1,Av_2, \\cdots , Av_n \\} $들도 직교할까? 직교한다. \n",
    "    - 왜냐하면 $ Av_i \\cdot Av_j = v_i \\cdot A^TAv_j = v_i \\cdot \\lambda_j v_j = \\lambda_j (v_i \\cdot v_j ) = 0 $이기 때문이다.\n",
    "    - 내적이 0이니까 직교하는 것이다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ \\lVert A v_i \\rVert = \\sqrt{\\lambda_i} \\;\\; (i=1,2,\\cdots,n) $이다. Why?\n",
    "    - $ \\lVert A v_i \\rVert^2 \n",
    "    = Av_i \\cdot Av_i \n",
    "    = v_i \\cdot A^T A v_i \n",
    "    = v_i \\cdot \\lambda v_i = \\lambda (v_i \\cdot v_i) = \\lambda \\lVert v_i \\rVert^2  $ 으로 풀이되고\n",
    "    - v는 정규화된 벡터이므로 $ \\lVert v_i \\rVert = 1$이므로 $ \\lambda \\lVert v_i \\rVert^2  = \\lambda $가 된다.\n",
    "    - 따라서 $ \\lVert A v_i \\rVert^2  = \\lambda  \\quad \\Rightarrow \\quad \\lVert A v_i \\rVert = \\sqrt{\\lambda} $이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ \\lVert A v_i \\rVert$ 는 직교인데, 정규화되어 있을가? 그렇지 않다.\n",
    "    1. 방금 $ \\lVert A v_i \\rVert = \\sqrt{\\lambda_i}  $임을 보았으므로, 반드시 1인 것은 아니다.\n",
    "    1. 정규화해보자. 간단하다. $ A v_i $을 $ \\sqrt{\\lambda_i} $로 나눠주면 된다.\n",
    "    1. $ \\{ \\frac{Av_1}{\\sqrt{\\lambda_1}}, \\frac{Av_2}{\\sqrt{\\lambda_2}}, \\cdots , \\frac{Av_n}{\\sqrt{\\lambda_n}} \\} $ 이렇게 정규화 할 수 있을 것 같은데\n",
    "    1. $ \\lambda_{k+1} = \\cdots = \\lambda_n = 0 $ 이므로 k까지만 나열해야 한다. 분모에 0이 있으면 안되니까\n",
    "    1. 정리하면 요렇게 된다. $ \\{ \\frac{Av_1}{\\sqrt{\\lambda_1}}, \\frac{Av_2}{\\sqrt{\\lambda_2}}, \\cdots , \\frac{Av_k}{\\sqrt{\\lambda_k}} \\} $\n",
    "        - 너무 복잡하니 $ \\frac{Av_i}{\\sqrt{\\lambda_i}} $를 $u_i$로 대체하자.\n",
    "        - 일단은 완성 $ \\{ \\frac{Av_1}{\\sqrt{\\lambda_1}}, \\frac{Av_2}{\\sqrt{\\lambda_2}}, \\cdots , \\frac{Av_k}{\\sqrt{\\lambda_k}} \\} = \\{ u_1, u_2, \\cdots , u_k \\} $\n",
    "        - 하지만 $ k+1 $부터 $n$까지는 나열하지 못했으니 기저가 되지는 못하겠다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ U = [ u_1, u_2, \\cdots , u_n ] $ 행렬 만들기, $u_i$는 열벡터\n",
    "\n",
    "    - u벡터들이 n개가 있어야 하는데 k개만 존재하므로 기저가 되지 못한다. \n",
    "    \n",
    "    - $u_{k+1}$부터 $u_n$까지의 벡터를 정규직교기저 만드는 법을 이용해서 채운다. [쑤튜브 71강 참고](https://www.youtube.com/watch?v=tk6HM0YVL5E&list=PLdEdazAwz5Q_n47tqf0QY94ASCmWqeGX1&index=79)\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\Sigma$ 행렬을 아래와 같이 만들었다고 생각해보자.\n",
    "\n",
    "$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sqrt{\\lambda_{1}} &                    &         &                    &            & \\\\\n",
    "                   & \\sqrt{\\lambda_{2}} &         &                    &   &        & \\\\\n",
    "                   &                    & \\ddots  &                    &   &        & \\\\\n",
    "                   &                    &         & \\sqrt{\\lambda_{k}} &   &        & \\\\\n",
    "                   &                    &         &                    & 0 &        & \\\\\n",
    "                   &                    &         &                    &   & \\ddots & \\\\\n",
    "                   &                    &         &                    &   &        & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad \n",
    "$ ( $n \\times n$  대각행렬 )\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 $U$와 $\\Sigma$ 를 곱해보자.\n",
    "    - $U \\Sigma = [\\sqrt{\\lambda_1} \\, u_1 , \\cdots , \\sqrt{\\lambda_k} \\, u_k , 0 \\cdots 0 ]$ 이므로\n",
    "    - $U \\Sigma = [Av_1, Av_2, \\cdots , Av_k , Av_{k+1}, Av_n ]$ 이 된다.\n",
    "    - 결국 $U \\Sigma = AV $이 되었다.\n",
    "    - 양변에 $ V^{-1} $를 곱하면 \n",
    "    $$ A = U \\Sigma V^{-1} = U \\Sigma V^T $$\n",
    "    \n",
    "- 증명 끝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A는 이런 식으로 분해할 수 있다.\n",
    "\n",
    "$$ A = U \\Sigma V^T $$\n",
    "\n",
    "- U는 어떤 모양?\n",
    "    - $ \\{ u_1, u_2, \\cdots , u_k \\} =\n",
    "        \\{ \\frac{Av_1}{\\sqrt{\\lambda_1}}, \\frac{Av_2}{\\sqrt{\\lambda_2}}, \\cdots , \\frac{Av_k}{\\sqrt{\\lambda_k}} \\}\n",
    "      $\n",
    "    - $ \\{ u_{k+1}, \\cdots , u_n \\}$는 정규직교기저 찾기를 통해서 찾은 벡터들이다.\n",
    "      \n",
    "- $\\Sigma$는 어떤 모양?\n",
    "\n",
    "$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sqrt{\\lambda_{1}} &                    &         &                    &            & \\\\\n",
    "                   & \\sqrt{\\lambda_{2}} &         &                    &   &        & \\\\\n",
    "                   &                    & \\ddots  &                    &   &        & \\\\\n",
    "                   &                    &         & \\sqrt{\\lambda_{k}} &   &        & \\\\\n",
    "                   &                    &         &                    & 0 &        & \\\\\n",
    "                   &                    &         &                    &   & \\ddots & \\\\\n",
    "                   &                    &         &                    &   &        & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad \n",
    "$ ( $n \\times n$  대각행렬 )\n",
    "\n",
    "- $V$는 어떤 모양?\n",
    "    - $A^TA$의 고유벡터들로 구성된 직교행렬(정규)\n",
    "    - 고유값 분해할때 배운 내용\n",
    "\n",
    "- $\\sqrt{\\lambda}$를 특이값이라고 한다. 그래서 특이값 분해라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 쑤튜브 강의 노트는 여기까지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나만의 정리\n",
    "\n",
    "### 계산하는 순서를 다시 한번 적어본다\n",
    "1. 대칭행렬이 아닌 n차 정방행렬 A가 있을때\n",
    "1. $A^TA$의 $\\lambda$와 고유벡터 V를 계산한다.\n",
    "1. 고유벡터 V를 정규화한다.\n",
    "1. 이렇게 찾은 $\\lambda$와 $V=[v_1, \\cdots, v_n ]$을 이용해서 $U$와 $\\Sigma$를 찾는다.\n",
    "1. U행렬 만들기\n",
    "    - $ \\{ u_1, u_2, \\cdots , u_k \\} =\n",
    "        \\{ \\frac{Av_1}{\\sqrt{\\lambda_1}}, \\frac{Av_2}{\\sqrt{\\lambda_2}}, \\cdots , \\frac{Av_k}{\\sqrt{\\lambda_k}} \\}\n",
    "      $\n",
    "    - $ \\{ u_{k+1}, \\cdots , u_n \\}$는 정규직교기저 찾기를 통해서 벡터들을 찾는다.\n",
    "1. $\\Sigma$ 대각행렬은 대각 원소가 $\\sqrt{\\lambda_i}$\n",
    "1. 이렇게 $A$행렬을 $ U \\Sigma V^T $로 분해했다.\n",
    "$$ A = U \\Sigma V^T $$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보충 자료\n",
    "### 유용한 링크\n",
    "- [다크프로그래머 블로그](https://darkpgmr.tistory.com/106) - 특이값 분해의 활용\n",
    "- [JamesKim 블로그](https://blog.naver.com/sdland85/90097444343) - 특이값 분해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다크프로그래머 블로그\n",
    "- 블로그에 설명이 잘 되어 있다.\n",
    "- 처음에는 이해를 못했는데, 쑤튜브 강의를 보고나니, 이제 이해가 된다.\n",
    "- SVD는 참 어려운 주제인 것 같다.\n",
    "- 개인적인 정리목적이라, 일부 생략했으니, 블로그 방문해서 읽는게 좋겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개요\n",
    "- 실수공간에서 임의의 m x n 행렬에 대한 특이값분해(SVD)는 다음과 같이 정의된다.\n",
    "\n",
    "$ A = U \\Sigma V^T $\n",
    "\n",
    "$ \\quad   U: m \\times n $ 직교행렬 $( AA^T = U (\\Sigma \\Sigma^T) U^T )$\n",
    "\n",
    "$ \\quad   V: n \\times n $ 직교행렬 $( A^T A = V (\\Sigma^T \\Sigma) V^T )$\n",
    "\n",
    "$ \\quad   \\Sigma = m \\times n $ 직사각 대각행렬\n",
    "\n",
    "- $U$는 $AA^T$를 고유값분해해서 얻어진 직교행렬(orthogonal matrix)로 U의 열벡터들은 A의 left singular vector라 부른다.\n",
    "- $V$는 $A^TA$를 고유값분해해서 얻어진 직교행렬로 V의 열벡터들을 A의 right singular vector라 부른다.\n",
    "- $\\Sigma$는 $A A^T , \\; A^TA $를 고유값 분해해서 나오는 고유값들의 square root를 대각원소로 하는 $m \\times n$ 직사각 대각행렬로 그 대각원소들을 A의 특이값(singular value)라 부른다.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $U,V$가 직교행렬(orthogonal matrix)이라 함은 $UU^T=VV^T=E, \\; U^{-1}=U^T , \\; V^{-1}=V^T$임도 기억하자.\n",
    "\n",
    "> U의 열벡터($u_i$): left singular vectors of A ($AA^T$의 eigenvector)\n",
    "\n",
    "\n",
    "> V의 열벡터($v_i$): right singular vectors of A ($A^TA$의 eigenvector)\n",
    "\n",
    "\n",
    ">$ \\Sigma $의 대각원소($\\sigma_i$): singular values of A ($A^TA, AA^T$의 eigenvalue들의 square root)\n",
    "\n",
    "$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sigma_{1} &         &          \\\\\n",
    "           & \\ddots  &          \\\\\n",
    "           &         & \\sigma_n \\\\\n",
    "           &         & 0        \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad (m > n) \n",
    "$\n",
    "\n",
    "$\n",
    "\\Sigma = \n",
    "\\begin{bmatrix}\n",
    "\\sigma_{1} &         &          &    \\\\\n",
    "           & \\ddots  &          &    \\\\\n",
    "           &         & \\sigma_n & 0  \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad  (m < n) \n",
    "$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전 글에서 설명했듯이 대칭행렬(symmetric matrix)은 \n",
    "    - 항상 고유값 분해(eigendecomposition)가 가능하며 \n",
    "    - 직교행렬(orthogonal matrix)로 대각화할 수 있다. \n",
    "- 그런데, $A A^T$와 $A^T A$는 모두 대칭행렬(symmetric matrix)이므로 위와 같은 고유값 분해가 항상 가능하다.\n",
    "\n",
    "\n",
    "**여기서 재미있는 사실은**\n",
    "- $AA^T$와 $A^TA$의 고유값들은 모두 0 이상(nonnegative)이며 \n",
    "\n",
    "- 0이 아닌 **고유값들은 서로 동일**하다는 점이다. \n",
    "\n",
    "- 고유값들이 0 이상이어야 square root를 씌울수 있으며 또한 서로 동일해야만 하나의 행렬 Σ로 표현할 수 있을 것이다.\n",
    "\n",
    "    - $A^TA$의 고유값을 λ, 고유벡터를 v (v≠0)라 했을 때, 정의에 의해 $A^TAv = \\lambda v$ 이다.\n",
    "        - 양변에 $v^T$를 곱해보면 $v^TA^TAv = \\lambda v^Tv$ 에서 $(Av)^TAv = \\lambda v^Tv$ \n",
    "        - 즉, $\\lVert Av \\rVert^2 = \\lambda  \\lVert v \\rVert^2 $ 이므로 λ≥0 이다.\n",
    "        \n",
    "    - $A^TA$의 0이 아닌 고유값을 λ, 고유벡터를 v (v≠0)라 했을 때, 정의에 의해 $(A^TA)v=\\lambda v$ 이다.\n",
    "        - 양변에 A를 곱해보면 $A(A^TA)v = \\lambda Av$ 즉, $AA^T(Av) = \\lambda (Av)$이므로 $Av \\ne 0$라면 λ는 또한 $AA^T$의 고유값임을 알 수 있다. \n",
    "        - 그런데, 만일 Av=0라 하면 $(A^TA)v = \\lambda v$에서 λ=0이어야 하므로 Av≠0이다. \n",
    "        - 동일한 방식으로 $AA^T$의 0이 아닌 모든 고유값도 또한 $A^TA$의 고유값이 됨을 쉽게 보일 수 있다.\n",
    "\n",
    "- 이와같이, $AA^T$와 $A^TA$의 공통의 고유값 $\\sigma_1^2 \\ge \\sigma_2^2 \\ge \\cdots \\ge \\sigma_s^2 \\ge 0$ (단, s = min(m, n))들을 구한 후\n",
    "\n",
    "- 이들의 square root를 취한 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_s \\ge 0$ 이 A의 특이값(singular value)들이고\n",
    "\n",
    "- 이들을 대각원소로 하는 m x n 직사각 대각행렬이 Σ이다 (식 (2)). 여기서 행렬의 특이값(singular value)은 모두 0 이상임을 기억하자.\n",
    "\n",
    "\n",
    "**참고로**\n",
    "\n",
    "행렬 A의 특이값(singular value)을 $\\sigma_i$, left singular vector를 $u_i$, right singular vector를 $v_i$라 했을 때\n",
    "\n",
    "다음 식이 성립한다.\n",
    "\n",
    "$$ Av_i = \\sigma_{i} u_{i}, \\quad 1 \\le i \\le s $$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※ 어떤 행렬 A가 singular하다는 말은 특이값 분해와는 조금 다른 말이다. \n",
    "- 행렬 A가 singular하다는 말은 정방행렬(square matrix)에 대해서만 해당되는 말로 A의 역행렬이 존재하지 않는다는 말이다. \n",
    "- 즉, det(A) = 0인 정방행렬을 특이행렬(singular matrix)이라고 부른다. \n",
    "- 단, 정방행렬에 대해서도 특이값 분해를 하게 되면 그 행렬이 singular한지 안한지를 바로 알 수 있다. \n",
    "- 정방행렬 A의 특이값들이 모두 0이 아니면 이 행렬은 nonsingular 즉, 역행렬이 존재하고 \n",
    "- 특이값 중 0이 포함되면 singular 즉, 역행렬이 존재하지 않는다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※ 특이값의 부호가 양수인 이유\n",
    "\n",
    "- 앞서 singular value는 $AA^T, A^TA$의 고유값분해(EVD)에서 나온 고유값의 square root를 취한 것이라고 했다. \n",
    "\n",
    "- 그런데, 고유값의 square root는 +, - 2개의 값이 나오는데 왜 +값만 singular value로 잡은 것일까? \n",
    "\n",
    "- 사실 원래는 singular value를 +로 잡을수도, -로 잡을수도 있다. \n",
    "\n",
    "- 하지만 +를 singular value로 잡는 것은 일종의 수학적 약속이다. \n",
    "\n",
    "- 만일 식 (1)에서 i번째 singular value의 부호를 바꿨을 때 U의 i번째 열벡터의 부호를 같이 바꾸면 식 (1)은 여전히 성립함을 알 수 있다.\n",
    "\n",
    "- 또한 U가 직교행렬(orthogonal matrix)란 점도 변하지 않는다. \n",
    "\n",
    "- 어쨌든, 특이값(singular value)은 항상 0 이상(nonnegative)임을 기억하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ※ positive definite, negative definite\n",
    "\n",
    "- 선형대수학에서 보면 가끔 어떤 행렬 A가 positive definite다, positive semidefinite다 하는 용어들이 나오는데 \n",
    "- 이는 **대칭행렬(symmetric matrix)**에 대해서만 정의되는 용어들로서 이 용어들의 정의는 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\forall{z} \\ne 0,  \\quad z^T A z \\gt 0 & \\quad \\rightarrow \\text{positive definite}\n",
    "\\newline\n",
    "\\forall{z} \\ne 0,  \\quad z^T A z \\ge 0 & \\quad \\rightarrow \\text{positive semi definite}\n",
    "\\newline\n",
    "\\forall{z} \\ne 0,  \\quad z^T A z \\lt 0 & \\quad \\rightarrow \\text{negative definite}\n",
    "\\newline\n",
    "\\forall{z} \\ne 0,  \\quad z^T A z \\le 0 & \\quad \\rightarrow \\text{negative semi definite}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- 즉, 어떤 대칭행렬 A가 영벡터가 아닌 모든 열벡터 z에 대해 항상 $z^TAz>0$을 만족할 때 \n",
    "이 행렬을 positive definite 행렬이라고 부르며 negative definite 등도 유사하게 정의된다. \n",
    "\n",
    "- 그런데 이러한 행렬들의 중요한 성질은 고유값(eigenvalue)도 동일한 부호를 갖는다는 점이다. \n",
    "\n",
    "- 즉, 어떤 대칭행렬 A가 positive definite하면 이 행렬의 모든 eigenvalue은 항상 양수이다. \n",
    "\n",
    "- 만일 A가 positive semidefinite하면 eigenvalue들도 ≥0이고, \n",
    "negative definite면 모든 eigenvalue들이 음수이다. \n",
    "\n",
    "- 앞서, SVD를 구하는 과정에서 나왔던 $AA^T, A^TA$는 positive semidefinite 행렬들로서 항상 0 이상의 eigenvalue들을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특이값분해(SVD)의 기하학적 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬을 x' = Ax와 같이 좌표공간에서의 선형변환으로 봤을 때 \n",
    "    - 직교행렬(orthogonal matrix)의 기하학적 의미는 회전변환(rotation transformation) 또는 반전된(reflected) 회전변환\n",
    "    - 대각행렬(diagonal maxtrix)의 기하학적 의미는 각 좌표성분으로의 스케일변환(scale transformation)이다.\n",
    "\n",
    "\n",
    "- 행렬 R이 직교행렬(orthogonal matrix)이라면 $RR^T = E$이다. \n",
    "    - 따라서 $det(RR^T) = det(R)det(R^T) = det(R)^2 = 1$이므로 det(R)는 항상 +1, 또는 -1이다. \n",
    "    - 만일 det(R)=1라면 이 직교행렬은 회전변환을 나타내고\n",
    "    - det(R)=-1라면 뒤집혀진(reflected) 회전변환을 나타낸다.\n",
    "\n",
    "- 따라서 식 (1), $A = U \\Sigma V^T$에서 U, V는 직교행렬, Σ는 대각행렬이므로 \n",
    "    - Ax는 x를 먼저 $V^T$에 의해 회전시킨 후 Σ로 스케일을 변화시키고 다시 U로 회전시키는 것임을 알 수 있다.\n",
    "\n",
    "![Singular-Value-Decomposition](https://t1.daumcdn.net/cfile/tistory/2725C84C5260AA5F28?download)\n",
    "<출처: [위키피디아](https://en.wikipedia.org/wiki/Singular_value_decomposition)>\n",
    "\n",
    "즉, 행렬의 특이값(singular value)이란 이 행렬로 표현되는 선형변환의 스케일 변환을 나타내는 값으로 해석할 수 있다. \n",
    "\n",
    "- 고유값분해(eigendecomposition)에서 나오는 고유값(eigenvalue)과 비교해 보면 \n",
    "- 고유값은 변환에 의해 불변인 방향벡터(-> 고유벡터)에 대한 스케일 factor이고, \n",
    "- 특이값은 변환 자체의 스케일 factor로 볼 수 있다.\n",
    "\n",
    "#### ☞ 이 주제와 관련하여 조금 더 상상의 나래를 펴 보면\n",
    "- m x n 행렬 A는 n차원 공간에서 m 차원 공간으로의 선형변환이다. \n",
    "- n차원 공간에 있는 원, 구 등과 같이 원형으로 된 도형을 A에 의해 변환시키면 \n",
    "- 먼저 $V^T$에 의해서는 회전만 일어나므로 도형의 형태는 변하지 않는다. \n",
    "- 그런데 Σ에 의해서는 특이값의 크기에 따라서 원이 타원이 되거나 구가 럭비공이 되는 것과 같은 식의 형태변환이 일어난다.\n",
    "    - n이 2차원인 원의 경우 첫번째 특이값 σ1은 변환된 타원의 주축의 길이\n",
    "    - 두번째 특이값 σ2는 단축의 길이에 대응된다\n",
    "- 이후 U에 의한 변환도 회전변환이므로 도형의 형태에는 영향을 미치지 못한다. \n",
    "- 만일 m>n이라면  0을 덧붙여서 차원을 확장한 후에 U로 회전을 시키는 것이고 \n",
    "- m<n이라면 일부 차원을 없애버리고(일종의 투영) 회전을 시키는 셈이다. \n",
    "- 결국 선형변환 A에 의한 도형의 변환결과는 형태적으로 보면 오로지 A의 특이값(singular value)들에 의해서만 결정된다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "기하학적 의미가 좀 어렵구나.\n",
    "나중에 더 정리해봐야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
